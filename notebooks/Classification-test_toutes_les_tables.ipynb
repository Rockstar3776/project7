{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6977f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8669b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"C:\\Users\\lcatteau\\Desktop\\data2p7\", index_col='SK_ID_CURR').drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e451c7f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TARGET</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT_x</th>\n",
       "      <th>AMT_ANNUITY_x</th>\n",
       "      <th>REGION_POPULATION_RELATIVE</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>DAYS_REGISTRATION</th>\n",
       "      <th>DAYS_ID_PUBLISH</th>\n",
       "      <th>...</th>\n",
       "      <th>SELLERPLACE_AREA</th>\n",
       "      <th>NAME_SELLER_INDUSTRY</th>\n",
       "      <th>CNT_PAYMENT</th>\n",
       "      <th>NAME_YIELD_GROUP</th>\n",
       "      <th>PRODUCT_COMBINATION</th>\n",
       "      <th>DAYS_FIRST_DRAWING</th>\n",
       "      <th>DAYS_FIRST_DUE</th>\n",
       "      <th>DAYS_LAST_DUE</th>\n",
       "      <th>DAYS_TERMINATION</th>\n",
       "      <th>NFLAG_INSURED_ON_APPROVAL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100002</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>406597.5</td>\n",
       "      <td>24700.5</td>\n",
       "      <td>0.018801</td>\n",
       "      <td>-9461</td>\n",
       "      <td>-637</td>\n",
       "      <td>-3648.0</td>\n",
       "      <td>-2120</td>\n",
       "      <td>...</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>365243.0</td>\n",
       "      <td>-565.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100003</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>1293502.5</td>\n",
       "      <td>35698.5</td>\n",
       "      <td>0.003541</td>\n",
       "      <td>-16765</td>\n",
       "      <td>-1188</td>\n",
       "      <td>-1186.0</td>\n",
       "      <td>-291</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>365243.0</td>\n",
       "      <td>-716.0</td>\n",
       "      <td>-1980.0</td>\n",
       "      <td>-527.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100004</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>6750.0</td>\n",
       "      <td>0.010032</td>\n",
       "      <td>-19046</td>\n",
       "      <td>-225</td>\n",
       "      <td>-4260.0</td>\n",
       "      <td>-2531</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>365243.0</td>\n",
       "      <td>-784.0</td>\n",
       "      <td>-724.0</td>\n",
       "      <td>-714.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100007</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>121500.0</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>21865.5</td>\n",
       "      <td>0.028663</td>\n",
       "      <td>-19932</td>\n",
       "      <td>-3038</td>\n",
       "      <td>-4311.0</td>\n",
       "      <td>-3458</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>20.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>365243.0</td>\n",
       "      <td>-344.0</td>\n",
       "      <td>-2056.0</td>\n",
       "      <td>365243.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100008</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99000.0</td>\n",
       "      <td>490495.5</td>\n",
       "      <td>27517.5</td>\n",
       "      <td>0.035792</td>\n",
       "      <td>-16941</td>\n",
       "      <td>-1588</td>\n",
       "      <td>-4970.0</td>\n",
       "      <td>-477</td>\n",
       "      <td>...</td>\n",
       "      <td>110</td>\n",
       "      <td>4</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>365243.0</td>\n",
       "      <td>-339.0</td>\n",
       "      <td>-2341.0</td>\n",
       "      <td>-66.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 139 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            TARGET  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT_x  \\\n",
       "SK_ID_CURR                                                         \n",
       "100002           1             0          202500.0      406597.5   \n",
       "100003           0             0          270000.0     1293502.5   \n",
       "100004           0             0           67500.0      135000.0   \n",
       "100007           0             0          121500.0      513000.0   \n",
       "100008           0             0           99000.0      490495.5   \n",
       "\n",
       "            AMT_ANNUITY_x  REGION_POPULATION_RELATIVE  DAYS_BIRTH  \\\n",
       "SK_ID_CURR                                                          \n",
       "100002            24700.5                    0.018801       -9461   \n",
       "100003            35698.5                    0.003541      -16765   \n",
       "100004             6750.0                    0.010032      -19046   \n",
       "100007            21865.5                    0.028663      -19932   \n",
       "100008            27517.5                    0.035792      -16941   \n",
       "\n",
       "            DAYS_EMPLOYED  DAYS_REGISTRATION  DAYS_ID_PUBLISH  ...  \\\n",
       "SK_ID_CURR                                                     ...   \n",
       "100002               -637            -3648.0            -2120  ...   \n",
       "100003              -1188            -1186.0             -291  ...   \n",
       "100004               -225            -4260.0            -2531  ...   \n",
       "100007              -3038            -4311.0            -3458  ...   \n",
       "100008              -1588            -4970.0             -477  ...   \n",
       "\n",
       "            SELLERPLACE_AREA  NAME_SELLER_INDUSTRY  CNT_PAYMENT  \\\n",
       "SK_ID_CURR                                                        \n",
       "100002                   500                     0    24.000000   \n",
       "100003                    -1                     4    10.000000   \n",
       "100004                    30                     2     4.000000   \n",
       "100007                    -1                     4    20.666667   \n",
       "100008                   110                     4    14.000000   \n",
       "\n",
       "            NAME_YIELD_GROUP  PRODUCT_COMBINATION  DAYS_FIRST_DRAWING  \\\n",
       "SK_ID_CURR                                                              \n",
       "100002                     3                   15            365243.0   \n",
       "100003                     4                    7            365243.0   \n",
       "100004                     4                   14            365243.0   \n",
       "100007                     1                    8            365243.0   \n",
       "100008                     3                    9            365243.0   \n",
       "\n",
       "            DAYS_FIRST_DUE  DAYS_LAST_DUE  DAYS_TERMINATION  \\\n",
       "SK_ID_CURR                                                    \n",
       "100002              -565.0          -25.0             -17.0   \n",
       "100003              -716.0        -1980.0            -527.0   \n",
       "100004              -784.0         -724.0            -714.0   \n",
       "100007              -344.0        -2056.0          365243.0   \n",
       "100008              -339.0        -2341.0             -66.0   \n",
       "\n",
       "            NFLAG_INSURED_ON_APPROVAL  \n",
       "SK_ID_CURR                             \n",
       "100002                            0.0  \n",
       "100003                            1.0  \n",
       "100004                            0.0  \n",
       "100007                            1.0  \n",
       "100008                            0.0  \n",
       "\n",
       "[5 rows x 139 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5f5edae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TARGET</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT_x</th>\n",
       "      <th>AMT_ANNUITY_x</th>\n",
       "      <th>REGION_POPULATION_RELATIVE</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>DAYS_REGISTRATION</th>\n",
       "      <th>DAYS_ID_PUBLISH</th>\n",
       "      <th>...</th>\n",
       "      <th>SELLERPLACE_AREA</th>\n",
       "      <th>NAME_SELLER_INDUSTRY</th>\n",
       "      <th>CNT_PAYMENT</th>\n",
       "      <th>NAME_YIELD_GROUP</th>\n",
       "      <th>PRODUCT_COMBINATION</th>\n",
       "      <th>DAYS_FIRST_DRAWING</th>\n",
       "      <th>DAYS_FIRST_DUE</th>\n",
       "      <th>DAYS_LAST_DUE</th>\n",
       "      <th>DAYS_TERMINATION</th>\n",
       "      <th>NFLAG_INSURED_ON_APPROVAL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100002</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>406597.5</td>\n",
       "      <td>24700.5</td>\n",
       "      <td>0.018801</td>\n",
       "      <td>-9461</td>\n",
       "      <td>-637</td>\n",
       "      <td>-3648.0</td>\n",
       "      <td>-2120</td>\n",
       "      <td>...</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>365243.0</td>\n",
       "      <td>-565.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100003</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>1293502.5</td>\n",
       "      <td>35698.5</td>\n",
       "      <td>0.003541</td>\n",
       "      <td>-16765</td>\n",
       "      <td>-1188</td>\n",
       "      <td>-1186.0</td>\n",
       "      <td>-291</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>365243.0</td>\n",
       "      <td>-716.0</td>\n",
       "      <td>-1980.0</td>\n",
       "      <td>-527.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100004</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>6750.0</td>\n",
       "      <td>0.010032</td>\n",
       "      <td>-19046</td>\n",
       "      <td>-225</td>\n",
       "      <td>-4260.0</td>\n",
       "      <td>-2531</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>365243.0</td>\n",
       "      <td>-784.0</td>\n",
       "      <td>-724.0</td>\n",
       "      <td>-714.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100007</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>121500.0</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>21865.5</td>\n",
       "      <td>0.028663</td>\n",
       "      <td>-19932</td>\n",
       "      <td>-3038</td>\n",
       "      <td>-4311.0</td>\n",
       "      <td>-3458</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>20.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>365243.0</td>\n",
       "      <td>-344.0</td>\n",
       "      <td>-2056.0</td>\n",
       "      <td>365243.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100008</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99000.0</td>\n",
       "      <td>490495.5</td>\n",
       "      <td>27517.5</td>\n",
       "      <td>0.035792</td>\n",
       "      <td>-16941</td>\n",
       "      <td>-1588</td>\n",
       "      <td>-4970.0</td>\n",
       "      <td>-477</td>\n",
       "      <td>...</td>\n",
       "      <td>110</td>\n",
       "      <td>4</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>365243.0</td>\n",
       "      <td>-339.0</td>\n",
       "      <td>-2341.0</td>\n",
       "      <td>-66.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456247</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>345510.0</td>\n",
       "      <td>17770.5</td>\n",
       "      <td>0.022800</td>\n",
       "      <td>-11870</td>\n",
       "      <td>-399</td>\n",
       "      <td>-675.0</td>\n",
       "      <td>-3936</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>7.750000</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>365243.0</td>\n",
       "      <td>-419.0</td>\n",
       "      <td>-2722.0</td>\n",
       "      <td>-321.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456249</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>22050.0</td>\n",
       "      <td>0.022800</td>\n",
       "      <td>-24384</td>\n",
       "      <td>365243</td>\n",
       "      <td>-7369.0</td>\n",
       "      <td>-2357</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>365243.0</td>\n",
       "      <td>-1495.0</td>\n",
       "      <td>-1165.0</td>\n",
       "      <td>-1156.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456253</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>153000.0</td>\n",
       "      <td>677664.0</td>\n",
       "      <td>29979.0</td>\n",
       "      <td>0.005002</td>\n",
       "      <td>-14966</td>\n",
       "      <td>-7921</td>\n",
       "      <td>-6737.0</td>\n",
       "      <td>-5150</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>365243.0</td>\n",
       "      <td>-1866.0</td>\n",
       "      <td>-2722.0</td>\n",
       "      <td>-1712.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456254</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>171000.0</td>\n",
       "      <td>370107.0</td>\n",
       "      <td>20205.0</td>\n",
       "      <td>0.005313</td>\n",
       "      <td>-11961</td>\n",
       "      <td>-4786</td>\n",
       "      <td>-2562.0</td>\n",
       "      <td>-931</td>\n",
       "      <td>...</td>\n",
       "      <td>63</td>\n",
       "      <td>2</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>365243.0</td>\n",
       "      <td>-247.0</td>\n",
       "      <td>365243.0</td>\n",
       "      <td>365243.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456255</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>157500.0</td>\n",
       "      <td>675000.0</td>\n",
       "      <td>49117.5</td>\n",
       "      <td>0.046220</td>\n",
       "      <td>-16856</td>\n",
       "      <td>-1262</td>\n",
       "      <td>-5128.0</td>\n",
       "      <td>-410</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>10</td>\n",
       "      <td>21.750000</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>365243.0</td>\n",
       "      <td>-425.0</td>\n",
       "      <td>-690.0</td>\n",
       "      <td>-64.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>247032 rows Ã— 139 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            TARGET  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT_x  \\\n",
       "SK_ID_CURR                                                         \n",
       "100002           1             0          202500.0      406597.5   \n",
       "100003           0             0          270000.0     1293502.5   \n",
       "100004           0             0           67500.0      135000.0   \n",
       "100007           0             0          121500.0      513000.0   \n",
       "100008           0             0           99000.0      490495.5   \n",
       "...            ...           ...               ...           ...   \n",
       "456247           0             0          112500.0      345510.0   \n",
       "456249           0             0          112500.0      225000.0   \n",
       "456253           0             0          153000.0      677664.0   \n",
       "456254           1             0          171000.0      370107.0   \n",
       "456255           0             0          157500.0      675000.0   \n",
       "\n",
       "            AMT_ANNUITY_x  REGION_POPULATION_RELATIVE  DAYS_BIRTH  \\\n",
       "SK_ID_CURR                                                          \n",
       "100002            24700.5                    0.018801       -9461   \n",
       "100003            35698.5                    0.003541      -16765   \n",
       "100004             6750.0                    0.010032      -19046   \n",
       "100007            21865.5                    0.028663      -19932   \n",
       "100008            27517.5                    0.035792      -16941   \n",
       "...                   ...                         ...         ...   \n",
       "456247            17770.5                    0.022800      -11870   \n",
       "456249            22050.0                    0.022800      -24384   \n",
       "456253            29979.0                    0.005002      -14966   \n",
       "456254            20205.0                    0.005313      -11961   \n",
       "456255            49117.5                    0.046220      -16856   \n",
       "\n",
       "            DAYS_EMPLOYED  DAYS_REGISTRATION  DAYS_ID_PUBLISH  ...  \\\n",
       "SK_ID_CURR                                                     ...   \n",
       "100002               -637            -3648.0            -2120  ...   \n",
       "100003              -1188            -1186.0             -291  ...   \n",
       "100004               -225            -4260.0            -2531  ...   \n",
       "100007              -3038            -4311.0            -3458  ...   \n",
       "100008              -1588            -4970.0             -477  ...   \n",
       "...                   ...                ...              ...  ...   \n",
       "456247               -399             -675.0            -3936  ...   \n",
       "456249             365243            -7369.0            -2357  ...   \n",
       "456253              -7921            -6737.0            -5150  ...   \n",
       "456254              -4786            -2562.0             -931  ...   \n",
       "456255              -1262            -5128.0             -410  ...   \n",
       "\n",
       "            SELLERPLACE_AREA  NAME_SELLER_INDUSTRY  CNT_PAYMENT  \\\n",
       "SK_ID_CURR                                                        \n",
       "100002                   500                     0    24.000000   \n",
       "100003                    -1                     4    10.000000   \n",
       "100004                    30                     2     4.000000   \n",
       "100007                    -1                     4    20.666667   \n",
       "100008                   110                     4    14.000000   \n",
       "...                      ...                   ...          ...   \n",
       "456247                    30                     2     7.750000   \n",
       "456249                    -1                     4    12.000000   \n",
       "456253                    22                     2     5.000000   \n",
       "456254                    63                     2    15.000000   \n",
       "456255                    -1                    10    21.750000   \n",
       "\n",
       "            NAME_YIELD_GROUP  PRODUCT_COMBINATION  DAYS_FIRST_DRAWING  \\\n",
       "SK_ID_CURR                                                              \n",
       "100002                     3                   15            365243.0   \n",
       "100003                     4                    7            365243.0   \n",
       "100004                     4                   14            365243.0   \n",
       "100007                     1                    8            365243.0   \n",
       "100008                     3                    9            365243.0   \n",
       "...                      ...                  ...                 ...   \n",
       "456247                     3                   13            365243.0   \n",
       "456249                     1                    3            365243.0   \n",
       "456253                     1                   13            365243.0   \n",
       "456254                     1                    9            365243.0   \n",
       "456255                     4                    8            365243.0   \n",
       "\n",
       "            DAYS_FIRST_DUE  DAYS_LAST_DUE  DAYS_TERMINATION  \\\n",
       "SK_ID_CURR                                                    \n",
       "100002              -565.0          -25.0             -17.0   \n",
       "100003              -716.0        -1980.0            -527.0   \n",
       "100004              -784.0         -724.0            -714.0   \n",
       "100007              -344.0        -2056.0          365243.0   \n",
       "100008              -339.0        -2341.0             -66.0   \n",
       "...                    ...            ...               ...   \n",
       "456247              -419.0        -2722.0            -321.0   \n",
       "456249             -1495.0        -1165.0           -1156.0   \n",
       "456253             -1866.0        -2722.0           -1712.0   \n",
       "456254              -247.0       365243.0          365243.0   \n",
       "456255              -425.0         -690.0             -64.0   \n",
       "\n",
       "            NFLAG_INSURED_ON_APPROVAL  \n",
       "SK_ID_CURR                             \n",
       "100002                            0.0  \n",
       "100003                            1.0  \n",
       "100004                            0.0  \n",
       "100007                            1.0  \n",
       "100008                            0.0  \n",
       "...                               ...  \n",
       "456247                            0.0  \n",
       "456249                            0.0  \n",
       "456253                            0.5  \n",
       "456254                            0.5  \n",
       "456255                            0.0  \n",
       "\n",
       "[247032 rows x 139 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9af219a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3c7edbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in data.columns:\n",
    "    if data[col].dtype == 'float64':\n",
    "        data[col] = data[col].astype('float32')\n",
    "for col in data.columns:\n",
    "    if data[col].dtype == 'int64':\n",
    "        data[col] = data[col].astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d73ec3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['TARGET']\n",
    "X = data.drop(columns='TARGET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3dbb60aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1000, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d958c41",
   "metadata": {},
   "source": [
    "# Dummy Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a36ac865",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture masquer_erreurs\n",
    "start = time.time()\n",
    "# DÃ©finir le modÃ¨le \n",
    "dummy = DummyClassifier(strategy=\"most_frequent\")\n",
    "\n",
    "# Adapter le modÃ¨le aux donnÃ©es d'entraÃ®nement\n",
    "dummy.fit(X_train, y_train)\n",
    "\n",
    "# Ã‰valuer la performance du modÃ¨le sur l'ensemble de test\n",
    "accuracy = dummy.score(X_test, y_test)\n",
    "print(\"PrÃ©cision sur l'ensemble de test:\", accuracy)\n",
    "y_predict = dummy.predict(X_test)\n",
    "print(\"PrÃ©cision sur l'AUC:\",roc_auc_score(y_test, y_predict))\n",
    "temps = time.time() - start\n",
    "print(temps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca05367d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PrÃ©cision sur l'ensemble de test: 0.917\n"
     ]
    }
   ],
   "source": [
    "print(\"PrÃ©cision sur l'ensemble de test:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7a7ced2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PrÃ©cision sur l'AUC: 0.5\n"
     ]
    }
   ],
   "source": [
    "print(\"PrÃ©cision sur l'AUC:\",roc_auc_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d891f0a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_predict)\n",
    "cm_matrix = pd.DataFrame(data=cm, columns=['Actual Positive:1', 'Actual Negative:0'], \n",
    "                                 index=['Predict Positive:1', 'Predict Negative:0'])\n",
    "\n",
    "sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2659aca5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "61a8de0d",
   "metadata": {},
   "source": [
    "# Logistic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b0ac9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture masquer_erreurs\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "start = time.time()\n",
    "# DÃ©finir le modÃ¨le de rÃ©gression logistique\n",
    "logistic_regression = LogisticRegression()\n",
    "\n",
    "# DÃ©finir la grille des hyperparamÃ¨tres Ã  rechercher\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100], 'penalty': ['l2']}\n",
    "\n",
    "# CrÃ©er l'objet GridSearchCV\n",
    "grid_search = GridSearchCV(logistic_regression, param_grid, cv=5, scoring='roc_auc', verbose =5)\n",
    "\n",
    "# Adapter le modÃ¨le aux donnÃ©es d'entraÃ®nement\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Afficher les meilleurs paramÃ¨tres trouvÃ©s\n",
    "print(\"Meilleurs paramÃ¨tres:\", grid_search.best_params_)\n",
    "print(\"Meilleur accuracy:\", grid_search.best_score_)\n",
    "# Ã‰valuer la performance du modÃ¨le sur l'ensemble de test\n",
    "accuracy = grid_search.score(X_test, y_test)\n",
    "print(\"PrÃ©cision sur l'ensemble de test:\", accuracy)\n",
    "y_predict = grid_search.predict(X_test)\n",
    "print(\"PrÃ©cision sur l'AUC:\",roc_auc_score(y_test, y_predict))\n",
    "temps = time.time() - start\n",
    "print(temps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a0690c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleurs paramÃ¨tres: {'C': 0.001, 'penalty': 'l2'}\n",
      "Meilleur accuracy: 0.6197013953934445\n",
      "PrÃ©cision sur l'ensemble de test: 0.6379498364231189\n",
      "PrÃ©cision sur l'AUC: 0.5\n"
     ]
    }
   ],
   "source": [
    "print(\"Meilleurs paramÃ¨tres:\", grid_search.best_params_)\n",
    "print(\"Meilleur accuracy:\", grid_search.best_score_)\n",
    "print(\"PrÃ©cision sur l'ensemble de test:\", accuracy)\n",
    "print(\"PrÃ©cision sur l'AUC:\",roc_auc_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99f92fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75a04b45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_matrix = pd.DataFrame(data=cm, columns=['Actual Positive:1', 'Actual Negative:0'], \n",
    "                                 index=['Predict Positive:1', 'Predict Negative:0'])\n",
    "\n",
    "sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f458865",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ad4cf88",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c77614df",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture masquer_erreurs\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "start = time.time()\n",
    "# DÃ©finir le modÃ¨le RandomForestClassifier\n",
    "random_forest = RandomForestClassifier(class_weight='balanced')\n",
    "\n",
    "# DÃ©finir la grille des hyperparamÃ¨tres Ã  rechercher\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# CrÃ©er l'objet GridSearchCV\n",
    "grid_search = GridSearchCV(random_forest, param_grid, cv=5, scoring='roc_auc', verbose=5)\n",
    "\n",
    "# Adapter le modÃ¨le aux donnÃ©es d'entraÃ®nement\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Afficher les meilleurs paramÃ¨tres trouvÃ©s\n",
    "print(\"Meilleurs paramÃ¨tres:\", grid_search.best_params_)\n",
    "print(\"Meilleur accuracy:\", grid_search.best_score_)\n",
    "# Ã‰valuer la performance du modÃ¨le sur l'ensemble de test\n",
    "accuracy = grid_search.score(X_test, y_test)\n",
    "print(\"PrÃ©cision sur l'ensemble de test:\", accuracy)\n",
    "temps = time.time() - start\n",
    "print(temps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc23433a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7766682871069884"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "720c900a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7530013743338257"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "943e2971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': None,\n",
       " 'min_samples_leaf': 4,\n",
       " 'min_samples_split': 10,\n",
       " 'n_estimators': 200}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6d8b5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = grid_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7bc6579f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5115029365006373"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "roc_auc_score(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406b3a3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c7d670",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d0ebddd",
   "metadata": {},
   "source": [
    "# Lightgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6469b4de",
   "metadata": {},
   "source": [
    "pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "38ce72d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bf6c8199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181464\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.069720 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13123\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15360, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.071773 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.066016 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.074024 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13117\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.071713 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13114\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181464\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.064761 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13123\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15360, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.066149 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.067294 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.067127 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13117\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.066395 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13114\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181464\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.067291 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13123\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15360, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.147427 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.060606 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.142905 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13117\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.070400 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13114\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181464\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.065138 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13123\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15360, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.060208 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.062837 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.074813 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13117\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.066564 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13114\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181464\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.067767 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13123\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15360, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.067717 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.068986 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.073990 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13117\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.069661 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13114\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181464\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.064939 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13123\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15360, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.070464 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.062328 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.068168 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13117\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.066363 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13114\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181464\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.068327 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13123\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15360, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.064119 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.156036 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.067404 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13117\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.066609 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13114\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181464\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.068791 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13123\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15360, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.060974 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.066160 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.068601 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13117\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.070548 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13114\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181464\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.063202 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13123\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15360, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.061147 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.060279 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.064822 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13117\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.062982 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13114\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181464\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.066020 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13123\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15360, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.063005 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.061218 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.070871 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13117\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.059570 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13114\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181464\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.071814 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13123\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15360, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.070250 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.068280 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.072066 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13117\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.067123 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13114\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181464\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.065878 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13123\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15360, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.066142 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.064478 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.064349 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13117\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.068616 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13114\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181464\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.070789 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13123\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 15360, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.067982 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.056618 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.069161 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13117\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.064369 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13114\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181464\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.067165 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13123\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15360, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.066468 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.066300 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.071566 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13117\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.056332 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13114\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181464\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.063226 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13123\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15360, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.069646 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.069328 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.070598 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13117\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.062330 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13114\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181464\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.060760 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13123\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15360, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.070071 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.070283 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.064345 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13117\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.061373 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13114\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181464\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.068224 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13123\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15360, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.063095 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.067570 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.065503 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13117\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.063480 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13114\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181464\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.065544 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13123\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 15360, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.063815 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.061729 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.063710 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13117\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.065267 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13114\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181464\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.062718 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13123\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15360, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.123339 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.066783 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.142239 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13117\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.063135 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13114\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181464\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.066557 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13123\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15360, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.066836 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.068611 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.064864 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13117\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.067796 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13114\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181464\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.126582 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13123\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15360, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.062839 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.073519 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.062947 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13117\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.061501 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13114\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181464\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.067390 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13123\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15360, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.141992 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.063687 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.066660 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13117\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.070003 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13114\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181464\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.060332 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13123\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15360, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.063540 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.056513 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.068426 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13117\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.072266 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13114\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181464\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.068911 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13123\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15360, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.063613 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.064917 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.062632 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13117\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.065758 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13114\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181464\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.069753 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13123\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15360, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.061911 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.059280 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.068003 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13117\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.061864 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13114\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181464\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.155464 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13123\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15360, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.070024 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.136884 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.059254 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13117\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.070088 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13114\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181464\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.068489 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13123\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15360, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.067919 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.061460 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.062880 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13117\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.067951 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13114\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181464\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.071231 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13123\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15360, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.061917 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.064647 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.067112 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13117\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.073103 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13114\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181464\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.064908 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13123\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15360, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.064791 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.066496 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.069477 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13117\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.144175 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13114\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181464\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.066535 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13123\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15360, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.064891 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.069405 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.068777 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13117\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.069589 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13114\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181464\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.064841 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13123\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15360, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.067540 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.070653 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.068773 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13117\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.066331 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13114\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181464\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.066956 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13123\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15360, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.064507 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.061170 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.061122 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13117\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.069999 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13114\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181464\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.063954 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13123\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 15360, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.067728 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.067536 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.074038 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13117\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.072732 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13114\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181464\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.062932 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13123\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15360, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.060980 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.068162 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.067327 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13117\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.131744 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13114\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181464\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.069137 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13123\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 15360, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.067499 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.069727 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.069564 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13117\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.066637 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13114\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181464\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.121650 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13123\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15360, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.069586 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.070303 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.063086 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13117\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.064584 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13114\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181464\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.060898 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13123\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15360, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.067708 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.065703 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.062806 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13117\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.065434 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13114\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181464\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.064787 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13123\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 15360, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.061028 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.060986 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.067764 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13117\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.061909 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13114\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181464\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.066805 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13123\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15360, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.069969 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.066861 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.068000 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13117\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.065625 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13114\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181464\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.069185 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13123\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15360, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.069075 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.069398 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.066236 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13117\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.064293 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13114\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181464\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.072935 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13123\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15360, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.066358 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.061180 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.062147 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13117\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.068854 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13114\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181464\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.064738 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13123\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15360, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.073070 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.070223 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.060599 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13117\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.066062 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13114\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181464\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.063150 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13123\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15360, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.068525 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.060488 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.062141 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13117\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.065973 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13114\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181464\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.065327 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13123\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15360, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.065316 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.061977 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.062414 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13117\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.066805 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13114\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181464\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.058053 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13123\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15360, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.063607 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.063591 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.059224 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13117\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.065150 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13114\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181464\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.065519 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13123\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15360, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.063494 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.060084 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.069134 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13117\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.064500 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13114\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181464\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.154132 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13123\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15360, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.069135 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.061038 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.063700 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13117\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.061658 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13114\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181464\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.069479 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13123\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15360, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.067819 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.068694 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.057477 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13117\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.063411 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13114\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181464\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.060649 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13123\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15360, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.058385 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.069088 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.068960 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13117\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.064555 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13114\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181464\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.067581 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13123\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15360, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.067433 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.069347 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.067124 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13117\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.069465 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13114\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181464\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.061072 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13123\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15360, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.068473 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.067102 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.067814 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13117\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.071563 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13114\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181464\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.069578 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13123\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15360, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.067795 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.059934 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.069463 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13117\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.065403 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13114\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181464\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.064377 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13123\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 15360, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.057488 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.068021 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.064671 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13117\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.067998 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13114\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181464\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.063609 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13123\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15360, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.068077 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.065892 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.062619 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13117\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.068536 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13114\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181464\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.067536 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13123\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15360, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.061403 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.072202 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.068357 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13117\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.058477 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13114\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181464\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.060569 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13123\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15360, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.070784 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.073168 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.068980 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13117\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.060885 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13114\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181464\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.067812 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13123\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15360, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.061082 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.067130 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.066753 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13117\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.068901 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13114\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181464\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.061947 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13123\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 15360, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.057312 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.064455 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.068443 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13117\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.068693 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13114\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181464\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.062511 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13123\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15360, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.067537 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.061944 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.065267 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13117\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.064975 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13114\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181464\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.066300 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13123\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 15360, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.064257 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196825, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.067440 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.071348 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13117\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 15361, number of negative: 181465\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.067148 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13114\n",
      "[LightGBM] [Info] Number of data points in the train set: 196826, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 19201, number of negative: 226831\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.074233 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108\n",
      "[LightGBM] [Info] Number of data points in the train set: 246032, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "1069.0935916900635\n"
     ]
    }
   ],
   "source": [
    "# DÃ©finir le modÃ¨le \n",
    "lightgbm = lgb.LGBMClassifier(class_weight='balanced')\n",
    "start = time.time()\n",
    "# DÃ©finir la grille des hyperparamÃ¨tres Ã  rechercher\n",
    "param_grid = {'boosting_type' : ['gbdt'], \n",
    "              'num_leaves' : [5, 10, 31,4, 5],\n",
    "              'max_depth' : [-1, 0, 10, 20], \n",
    "              'learning_rate' : [0.1, 0.5, 0.7]\n",
    "              #n_estimators=100\n",
    "             }\n",
    "\n",
    "\n",
    "# CrÃ©er l'objet GridSearchCV\n",
    "grid_search = GridSearchCV(lightgbm, param_grid, cv=5, scoring='roc_auc')\n",
    "\n",
    "# Adapter le modÃ¨le aux donnÃ©es d'entraÃ®nement\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Afficher les meilleurs paramÃ¨tres trouvÃ©s\n",
    "accuracy = grid_search.score(X_test, y_test)\n",
    "y_predict = grid_search.predict(X_test)\n",
    "temps = time.time() - start\n",
    "print(temps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f6699012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleurs paramÃ¨tres: {'boosting_type': 'gbdt', 'learning_rate': 0.1, 'max_depth': 10, 'num_leaves': 31}\n",
      "Meilleur accuracy: 0.7681609447017651\n",
      "PrÃ©cision sur l'AUC: 0.7239886481586105\n",
      "PrÃ©cision sur l'ensemble de test: 0.7860099065838053\n"
     ]
    }
   ],
   "source": [
    "print(\"Meilleurs paramÃ¨tres:\", grid_search.best_params_)\n",
    "print(\"Meilleur accuracy:\", grid_search.best_score_)\n",
    "print(\"PrÃ©cision sur l'AUC:\",roc_auc_score(y_test, y_predict))\n",
    "print(\"PrÃ©cision sur l'ensemble de test:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0511dac6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "82959f02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_predict)\n",
    "cm_matrix = pd.DataFrame(data=cm, columns=['Actual Positive:1', 'Actual Negative:0'], \n",
    "                                 index=['Predict Positive:1', 'Predict Negative:0'])\n",
    "\n",
    "sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "48a190d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pour mettre en place un predict proba avec un seuil de 0.6 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "76d6b5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    }
   ],
   "source": [
    "df_pred = pd.DataFrame(grid_search.predict_proba(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1b2f2f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(row):\n",
    "    if row[1]>=0.75 :\n",
    "         return 1\n",
    "    else :\n",
    "        return 0\n",
    "\n",
    "df_pred['pred_reel'] = df_pred.apply(lambda row : prediction(row),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4e1517ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, df_pred['pred_reel'])\n",
    "cm_matrix = pd.DataFrame(data=cm, columns=['Actual Positive:1', 'Actual Negative:0'], \n",
    "                                 index=['Predict Positive:1', 'Predict Negative:0'])\n",
    "\n",
    "sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9336e70a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25946d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519f2826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DÃ©finir le modÃ¨le \n",
    "svm = SVC(class_weight='balanced')\n",
    "\n",
    "# DÃ©finir la grille des hyperparamÃ¨tres Ã  rechercher\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100], \n",
    "              'kernel' : ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "             }\n",
    "\n",
    "\n",
    "# CrÃ©er l'objet GridSearchCV\n",
    "grid_search = GridSearchCV(svm, param_grid, cv=5, scoring='roc_auc')\n",
    "\n",
    "# Adapter le modÃ¨le aux donnÃ©es d'entraÃ®nement\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Afficher les meilleurs paramÃ¨tres trouvÃ©s\n",
    "accuracy = grid_search.score(X_test, y_test)\n",
    "y_predict = grid_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdbd79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Meilleurs paramÃ¨tres:\", grid_search.best_params_)\n",
    "print(\"Meilleur accuracy:\", grid_search.best_score_)\n",
    "print(\"PrÃ©cision sur l'AUC:\",roc_auc_score(y_test, y_predict))\n",
    "print(\"PrÃ©cision sur l'ensemble de test:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fc144f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_predict)\n",
    "cm_matrix = pd.DataFrame(data=cm, columns=['Actual Positive:1', 'Actual Negative:0'], \n",
    "                                 index=['Predict Positive:1', 'Predict Negative:0'])\n",
    "\n",
    "sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2966381c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1829124",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f64001c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
