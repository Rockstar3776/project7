{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6977f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8669b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"C:\\Users\\lcatteau\\Desktop\\datap7\", index_col='SK_ID_CURR').drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e451c7f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TARGET</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>REGION_POPULATION_RELATIVE</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>DAYS_REGISTRATION</th>\n",
       "      <th>DAYS_ID_PUBLISH</th>\n",
       "      <th>...</th>\n",
       "      <th>NAME_INCOME_TYPE_enc</th>\n",
       "      <th>NAME_EDUCATION_TYPE_enc</th>\n",
       "      <th>NAME_FAMILY_STATUS_enc</th>\n",
       "      <th>NAME_HOUSING_TYPE_enc</th>\n",
       "      <th>OCCUPATION_TYPE_enc</th>\n",
       "      <th>WEEKDAY_APPR_PROCESS_START_enc</th>\n",
       "      <th>ORGANIZATION_TYPE_enc</th>\n",
       "      <th>FONDKAPREMONT_MODE_enc</th>\n",
       "      <th>HOUSETYPE_MODE_enc</th>\n",
       "      <th>WALLSMATERIAL_MODE_enc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100002</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.615</td>\n",
       "      <td>-0.198521</td>\n",
       "      <td>-0.011205</td>\n",
       "      <td>-0.002626</td>\n",
       "      <td>0.865181</td>\n",
       "      <td>0.233104</td>\n",
       "      <td>0.156504</td>\n",
       "      <td>0.439705</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100003</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.365</td>\n",
       "      <td>1.448012</td>\n",
       "      <td>0.597361</td>\n",
       "      <td>-0.820550</td>\n",
       "      <td>-0.139634</td>\n",
       "      <td>0.010117</td>\n",
       "      <td>0.606637</td>\n",
       "      <td>1.148895</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100004</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.885</td>\n",
       "      <td>-0.702740</td>\n",
       "      <td>-1.004482</td>\n",
       "      <td>-0.472638</td>\n",
       "      <td>-0.453432</td>\n",
       "      <td>0.399838</td>\n",
       "      <td>0.044611</td>\n",
       "      <td>0.280341</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100006</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.135</td>\n",
       "      <td>-0.372874</td>\n",
       "      <td>0.264691</td>\n",
       "      <td>-0.580533</td>\n",
       "      <td>-0.447792</td>\n",
       "      <td>-0.738972</td>\n",
       "      <td>-0.974312</td>\n",
       "      <td>0.316789</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100007</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.285</td>\n",
       "      <td>-0.000986</td>\n",
       "      <td>-0.168078</td>\n",
       "      <td>0.525969</td>\n",
       "      <td>-0.575320</td>\n",
       "      <td>-0.738567</td>\n",
       "      <td>0.035287</td>\n",
       "      <td>-0.079100</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            TARGET  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  \\\n",
       "SK_ID_CURR                                                                    \n",
       "100002           1           0.0             0.615   -0.198521    -0.011205   \n",
       "100003           0           0.0             1.365    1.448012     0.597361   \n",
       "100004           0           0.0            -0.885   -0.702740    -1.004482   \n",
       "100006           0           0.0            -0.135   -0.372874     0.264691   \n",
       "100007           0           0.0            -0.285   -0.000986    -0.168078   \n",
       "\n",
       "            REGION_POPULATION_RELATIVE  DAYS_BIRTH  DAYS_EMPLOYED  \\\n",
       "SK_ID_CURR                                                          \n",
       "100002                       -0.002626    0.865181       0.233104   \n",
       "100003                       -0.820550   -0.139634       0.010117   \n",
       "100004                       -0.472638   -0.453432       0.399838   \n",
       "100006                       -0.580533   -0.447792      -0.738972   \n",
       "100007                        0.525969   -0.575320      -0.738567   \n",
       "\n",
       "            DAYS_REGISTRATION  DAYS_ID_PUBLISH  ...  NAME_INCOME_TYPE_enc  \\\n",
       "SK_ID_CURR                                      ...                         \n",
       "100002               0.156504         0.439705  ...                     7   \n",
       "100003               0.606637         1.148895  ...                     4   \n",
       "100004               0.044611         0.280341  ...                     7   \n",
       "100006              -0.974312         0.316789  ...                     7   \n",
       "100007               0.035287        -0.079100  ...                     7   \n",
       "\n",
       "            NAME_EDUCATION_TYPE_enc  NAME_FAMILY_STATUS_enc  \\\n",
       "SK_ID_CURR                                                    \n",
       "100002                            4                       3   \n",
       "100003                            1                       1   \n",
       "100004                            4                       3   \n",
       "100006                            4                       0   \n",
       "100007                            4                       3   \n",
       "\n",
       "            NAME_HOUSING_TYPE_enc  OCCUPATION_TYPE_enc  \\\n",
       "SK_ID_CURR                                               \n",
       "100002                          1                    8   \n",
       "100003                          1                    3   \n",
       "100004                          1                    8   \n",
       "100006                          1                    8   \n",
       "100007                          1                    3   \n",
       "\n",
       "            WEEKDAY_APPR_PROCESS_START_enc  ORGANIZATION_TYPE_enc  \\\n",
       "SK_ID_CURR                                                          \n",
       "100002                                   6                      5   \n",
       "100003                                   1                     39   \n",
       "100004                                   1                     11   \n",
       "100006                                   6                      5   \n",
       "100007                                   4                     37   \n",
       "\n",
       "            FONDKAPREMONT_MODE_enc  HOUSETYPE_MODE_enc  WALLSMATERIAL_MODE_enc  \n",
       "SK_ID_CURR                                                                      \n",
       "100002                           2                   0                       5  \n",
       "100003                           2                   0                       0  \n",
       "100004                           2                   0                       4  \n",
       "100006                           2                   0                       4  \n",
       "100007                           2                   0                       4  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5f5edae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TARGET</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>REGION_POPULATION_RELATIVE</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>DAYS_REGISTRATION</th>\n",
       "      <th>DAYS_ID_PUBLISH</th>\n",
       "      <th>...</th>\n",
       "      <th>NAME_INCOME_TYPE_enc</th>\n",
       "      <th>NAME_EDUCATION_TYPE_enc</th>\n",
       "      <th>NAME_FAMILY_STATUS_enc</th>\n",
       "      <th>NAME_HOUSING_TYPE_enc</th>\n",
       "      <th>OCCUPATION_TYPE_enc</th>\n",
       "      <th>WEEKDAY_APPR_PROCESS_START_enc</th>\n",
       "      <th>ORGANIZATION_TYPE_enc</th>\n",
       "      <th>FONDKAPREMONT_MODE_enc</th>\n",
       "      <th>HOUSETYPE_MODE_enc</th>\n",
       "      <th>WALLSMATERIAL_MODE_enc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100002</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.615</td>\n",
       "      <td>-0.198521</td>\n",
       "      <td>-0.011205</td>\n",
       "      <td>-0.002626</td>\n",
       "      <td>0.865181</td>\n",
       "      <td>0.233104</td>\n",
       "      <td>0.156504</td>\n",
       "      <td>0.439705</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100003</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.365</td>\n",
       "      <td>1.448012</td>\n",
       "      <td>0.597361</td>\n",
       "      <td>-0.820550</td>\n",
       "      <td>-0.139634</td>\n",
       "      <td>0.010117</td>\n",
       "      <td>0.606637</td>\n",
       "      <td>1.148895</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100004</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.885</td>\n",
       "      <td>-0.702740</td>\n",
       "      <td>-1.004482</td>\n",
       "      <td>-0.472638</td>\n",
       "      <td>-0.453432</td>\n",
       "      <td>0.399838</td>\n",
       "      <td>0.044611</td>\n",
       "      <td>0.280341</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100006</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.135</td>\n",
       "      <td>-0.372874</td>\n",
       "      <td>0.264691</td>\n",
       "      <td>-0.580533</td>\n",
       "      <td>-0.447792</td>\n",
       "      <td>-0.738972</td>\n",
       "      <td>-0.974312</td>\n",
       "      <td>0.316789</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100007</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.285</td>\n",
       "      <td>-0.000986</td>\n",
       "      <td>-0.168078</td>\n",
       "      <td>0.525969</td>\n",
       "      <td>-0.575320</td>\n",
       "      <td>-0.738567</td>\n",
       "      <td>0.035287</td>\n",
       "      <td>-0.079100</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456251</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.115</td>\n",
       "      <td>-0.480518</td>\n",
       "      <td>0.146912</td>\n",
       "      <td>0.734898</td>\n",
       "      <td>0.883615</td>\n",
       "      <td>0.395386</td>\n",
       "      <td>-0.722552</td>\n",
       "      <td>0.493214</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456252</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.835</td>\n",
       "      <td>-0.452949</td>\n",
       "      <td>-0.713894</td>\n",
       "      <td>0.338425</td>\n",
       "      <td>-0.691292</td>\n",
       "      <td>148.302711</td>\n",
       "      <td>0.021209</td>\n",
       "      <td>-0.324157</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456253</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.304712</td>\n",
       "      <td>0.280876</td>\n",
       "      <td>-0.742242</td>\n",
       "      <td>0.107855</td>\n",
       "      <td>-2.714690</td>\n",
       "      <td>-0.408264</td>\n",
       "      <td>-0.735169</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>39</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456254</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.265</td>\n",
       "      <td>-0.266266</td>\n",
       "      <td>-0.259960</td>\n",
       "      <td>-0.725572</td>\n",
       "      <td>0.521255</td>\n",
       "      <td>-1.445973</td>\n",
       "      <td>0.355060</td>\n",
       "      <td>0.900737</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456255</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.299766</td>\n",
       "      <td>1.339890</td>\n",
       "      <td>1.467010</td>\n",
       "      <td>-0.152153</td>\n",
       "      <td>-0.019830</td>\n",
       "      <td>-0.114087</td>\n",
       "      <td>1.102753</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>307511 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            TARGET  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  \\\n",
       "SK_ID_CURR                                                                    \n",
       "100002           1           0.0             0.615   -0.198521    -0.011205   \n",
       "100003           0           0.0             1.365    1.448012     0.597361   \n",
       "100004           0           0.0            -0.885   -0.702740    -1.004482   \n",
       "100006           0           0.0            -0.135   -0.372874     0.264691   \n",
       "100007           0           0.0            -0.285   -0.000986    -0.168078   \n",
       "...            ...           ...               ...         ...          ...   \n",
       "456251           0           0.0             0.115   -0.480518     0.146912   \n",
       "456252           0           0.0            -0.835   -0.452949    -0.713894   \n",
       "456253           0           0.0             0.065    0.304712     0.280876   \n",
       "456254           1           0.0             0.265   -0.266266    -0.259960   \n",
       "456255           0           0.0             0.115    0.299766     1.339890   \n",
       "\n",
       "            REGION_POPULATION_RELATIVE  DAYS_BIRTH  DAYS_EMPLOYED  \\\n",
       "SK_ID_CURR                                                          \n",
       "100002                       -0.002626    0.865181       0.233104   \n",
       "100003                       -0.820550   -0.139634       0.010117   \n",
       "100004                       -0.472638   -0.453432       0.399838   \n",
       "100006                       -0.580533   -0.447792      -0.738972   \n",
       "100007                        0.525969   -0.575320      -0.738567   \n",
       "...                                ...         ...            ...   \n",
       "456251                        0.734898    0.883615       0.395386   \n",
       "456252                        0.338425   -0.691292     148.302711   \n",
       "456253                       -0.742242    0.107855      -2.714690   \n",
       "456254                       -0.725572    0.521255      -1.445973   \n",
       "456255                        1.467010   -0.152153      -0.019830   \n",
       "\n",
       "            DAYS_REGISTRATION  DAYS_ID_PUBLISH  ...  NAME_INCOME_TYPE_enc  \\\n",
       "SK_ID_CURR                                      ...                         \n",
       "100002               0.156504         0.439705  ...                     7   \n",
       "100003               0.606637         1.148895  ...                     4   \n",
       "100004               0.044611         0.280341  ...                     7   \n",
       "100006              -0.974312         0.316789  ...                     7   \n",
       "100007               0.035287        -0.079100  ...                     7   \n",
       "...                       ...              ...  ...                   ...   \n",
       "456251              -0.722552         0.493214  ...                     7   \n",
       "456252               0.021209        -0.324157  ...                     3   \n",
       "456253              -0.408264        -0.735169  ...                     7   \n",
       "456254               0.355060         0.900737  ...                     1   \n",
       "456255              -0.114087         1.102753  ...                     1   \n",
       "\n",
       "            NAME_EDUCATION_TYPE_enc  NAME_FAMILY_STATUS_enc  \\\n",
       "SK_ID_CURR                                                    \n",
       "100002                            4                       3   \n",
       "100003                            1                       1   \n",
       "100004                            4                       3   \n",
       "100006                            4                       0   \n",
       "100007                            4                       3   \n",
       "...                             ...                     ...   \n",
       "456251                            4                       2   \n",
       "456252                            4                       5   \n",
       "456253                            1                       2   \n",
       "456254                            4                       1   \n",
       "456255                            1                       1   \n",
       "\n",
       "            NAME_HOUSING_TYPE_enc  OCCUPATION_TYPE_enc  \\\n",
       "SK_ID_CURR                                               \n",
       "100002                          1                    8   \n",
       "100003                          1                    3   \n",
       "100004                          1                    8   \n",
       "100006                          1                    8   \n",
       "100007                          1                    3   \n",
       "...                           ...                  ...   \n",
       "456251                          5                   14   \n",
       "456252                          1                    8   \n",
       "456253                          1                   10   \n",
       "456254                          1                    8   \n",
       "456255                          1                    8   \n",
       "\n",
       "            WEEKDAY_APPR_PROCESS_START_enc  ORGANIZATION_TYPE_enc  \\\n",
       "SK_ID_CURR                                                          \n",
       "100002                                   6                      5   \n",
       "100003                                   1                     39   \n",
       "100004                                   1                     11   \n",
       "100006                                   6                      5   \n",
       "100007                                   4                     37   \n",
       "...                                    ...                    ...   \n",
       "456251                                   4                     43   \n",
       "456252                                   1                     57   \n",
       "456253                                   4                     39   \n",
       "456254                                   6                      3   \n",
       "456255                                   4                      5   \n",
       "\n",
       "            FONDKAPREMONT_MODE_enc  HOUSETYPE_MODE_enc  WALLSMATERIAL_MODE_enc  \n",
       "SK_ID_CURR                                                                      \n",
       "100002                           2                   0                       5  \n",
       "100003                           2                   0                       0  \n",
       "100004                           2                   0                       4  \n",
       "100006                           2                   0                       4  \n",
       "100007                           2                   0                       4  \n",
       "...                            ...                 ...                     ...  \n",
       "456251                           2                   0                       5  \n",
       "456252                           2                   0                       5  \n",
       "456253                           2                   0                       4  \n",
       "456254                           2                   0                       5  \n",
       "456255                           2                   0                       4  \n",
       "\n",
       "[307511 rows x 58 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9af219a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3c7edbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in data.columns:\n",
    "    if data[col].dtype == 'float64':\n",
    "        data[col] = data[col].astype('float32')\n",
    "for col in data.columns:\n",
    "    if data[col].dtype == 'int64':\n",
    "        data[col] = data[col].astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d73ec3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['TARGET']\n",
    "X = data.drop(columns='TARGET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3dbb60aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1000, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de6454b",
   "metadata": {},
   "source": [
    "# Dummy Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a36ac865",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture masquer_erreurs\n",
    "start = time.time()\n",
    "# DÃ©finir le modÃ¨le \n",
    "dummy = DummyClassifier(strategy=\"most_frequent\")\n",
    "\n",
    "# Adapter le modÃ¨le aux donnÃ©es d'entraÃ®nement\n",
    "dummy.fit(X_train, y_train)\n",
    "\n",
    "# Ã‰valuer la performance du modÃ¨le sur l'ensemble de test\n",
    "accuracy = dummy.score(X_test, y_test)\n",
    "print(\"PrÃ©cision sur l'ensemble de test:\", accuracy)\n",
    "y_predict = dummy.predict(X_test)\n",
    "print(\"PrÃ©cision sur l'AUC:\",roc_auc_score(y_test, y_predict))\n",
    "temps = time.time() - start\n",
    "print(temps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca05367d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PrÃ©cision sur l'ensemble de test: 0.907\n"
     ]
    }
   ],
   "source": [
    "print(\"PrÃ©cision sur l'ensemble de test:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7a7ced2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PrÃ©cision sur l'AUC: 0.5\n"
     ]
    }
   ],
   "source": [
    "print(\"PrÃ©cision sur l'AUC:\",roc_auc_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d891f0a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_predict)\n",
    "cm_matrix = pd.DataFrame(data=cm, columns=['Actual Positive:1', 'Actual Negative:0'], \n",
    "                                 index=['Predict Positive:1', 'Predict Negative:0'])\n",
    "\n",
    "sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2659aca5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d782f83",
   "metadata": {},
   "source": [
    "# Logistic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b0ac9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture masquer_erreurs\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "start = time.time()\n",
    "\n",
    "# DÃ©finir le modÃ¨le de rÃ©gression logistique\n",
    "logistic_regression = LogisticRegression()\n",
    "\n",
    "# DÃ©finir la grille des hyperparamÃ¨tres Ã  rechercher\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100], 'penalty': ['l2']}\n",
    "\n",
    "# CrÃ©er l'objet GridSearchCV\n",
    "grid_search = GridSearchCV(logistic_regression, param_grid, cv=5, scoring='roc_auc', verbose =5)\n",
    "\n",
    "# Adapter le modÃ¨le aux donnÃ©es d'entraÃ®nement\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Afficher les meilleurs paramÃ¨tres trouvÃ©s\n",
    "print(\"Meilleurs paramÃ¨tres:\", grid_search.best_params_)\n",
    "print(\"Meilleur accuracy:\", grid_search.best_score_)\n",
    "# Ã‰valuer la performance du modÃ¨le sur l'ensemble de test\n",
    "accuracy = grid_search.score(X_test, y_test)\n",
    "print(\"PrÃ©cision sur l'ensemble de test:\", accuracy)\n",
    "y_predict = grid_search.predict(X_test)\n",
    "print(\"PrÃ©cision sur l'AUC:\",roc_auc_score(y_test, y_predict))\n",
    "temps = time.time() - start\n",
    "print(temps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a0690c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleurs paramÃ¨tres: {'C': 0.1, 'penalty': 'l2'}\n",
      "Meilleur accuracy: 0.7150918513969209\n",
      "PrÃ©cision sur l'ensemble de test: 0.7114438477315029\n",
      "PrÃ©cision sur l'AUC: 0.5\n"
     ]
    }
   ],
   "source": [
    "print(\"Meilleurs paramÃ¨tres:\", grid_search.best_params_)\n",
    "print(\"Meilleur accuracy:\", grid_search.best_score_)\n",
    "print(\"PrÃ©cision sur l'ensemble de test:\", accuracy)\n",
    "print(\"PrÃ©cision sur l'AUC:\",roc_auc_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99f92fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75a04b45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_matrix = pd.DataFrame(data=cm, columns=['Actual Positive:1', 'Actual Negative:0'], \n",
    "                                 index=['Predict Positive:1', 'Predict Negative:0'])\n",
    "\n",
    "sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f458865",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ca7d8e0",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c77614df",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture masquer_erreurs\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "start = time.time()\n",
    "# DÃ©finir le modÃ¨le RandomForestClassifier\n",
    "random_forest = RandomForestClassifier(class_weight='balanced')\n",
    "\n",
    "# DÃ©finir la grille des hyperparamÃ¨tres Ã  rechercher\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# CrÃ©er l'objet GridSearchCV\n",
    "grid_search = GridSearchCV(random_forest, param_grid, cv=5, scoring='roc_auc', verbose=5)\n",
    "\n",
    "# Adapter le modÃ¨le aux donnÃ©es d'entraÃ®nement\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Afficher les meilleurs paramÃ¨tres trouvÃ©s\n",
    "print(\"Meilleurs paramÃ¨tres:\", grid_search.best_params_)\n",
    "print(\"Meilleur accuracy:\", grid_search.best_score_)\n",
    "# Ã‰valuer la performance du modÃ¨le sur l'ensemble de test\n",
    "accuracy = grid_search.score(X_test, y_test)\n",
    "print(\"PrÃ©cision sur l'ensemble de test:\", accuracy)\n",
    "temps = time.time() - start\n",
    "print(temps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc23433a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7226588896397198"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "720c900a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7439501201313761"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "943e2971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': None,\n",
       " 'min_samples_leaf': 4,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 200}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6d8b5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = grid_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7bc6579f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5230228450166565"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "roc_auc_score(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406b3a3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c7d670",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d6f5307d",
   "metadata": {},
   "source": [
    "# Lightgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf2185e",
   "metadata": {},
   "source": [
    "pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "38ce72d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bf6c8199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044256 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245208, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043278 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3947\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046112 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3942\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041408 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225424\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045935 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3948\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.048291 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245208, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043363 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3947\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041671 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3942\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041963 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225424\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040816 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3948\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046213 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245208, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044722 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3947\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047383 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3942\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044560 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225424\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043394 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3948\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039168 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245208, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045736 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3947\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046988 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3942\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042340 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225424\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047119 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3948\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040540 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245208, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044141 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3947\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040574 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3942\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041858 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225424\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044765 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3948\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044577 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245208, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040321 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3947\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047060 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3942\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046418 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225424\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042032 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3948\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047153 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245208, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.037400 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3947\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043971 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3942\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041379 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225424\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044613 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3948\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044335 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245208, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044558 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3947\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041281 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3942\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041615 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225424\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041721 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3948\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041151 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245208, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042188 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3947\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044771 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3942\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043907 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225424\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.050739 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3948\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041850 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245208, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039431 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3947\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045187 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3942\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.037268 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225424\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044898 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3948\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044371 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245208, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041187 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3947\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044462 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3942\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039516 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225424\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.048598 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3948\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044407 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245208, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041464 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3947\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043444 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3942\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044191 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225424\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041781 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3948\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047241 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245208, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044236 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3947\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040624 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3942\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046582 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225424\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043128 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3948\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045071 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245208, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043866 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3947\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042290 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3942\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040792 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225424\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042444 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3948\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046263 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245208, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039879 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3947\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039351 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3942\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043582 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225424\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047293 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3948\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043701 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245208, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045505 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3947\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041005 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3942\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042483 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225424\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044753 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3948\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046301 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245208, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039110 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3947\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.048172 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3942\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042010 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225424\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044221 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3948\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044304 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245208, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045885 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3947\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043510 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3942\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040382 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225424\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043683 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3948\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040041 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245208, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041515 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3947\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045798 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3942\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041260 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225424\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046902 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3948\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041149 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245208, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042321 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3947\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.049373 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3942\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042652 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225424\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044201 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3948\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046579 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245208, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039371 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3947\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046167 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3942\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044303 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225424\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042157 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3948\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044400 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245208, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044994 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3947\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046528 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3942\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045862 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225424\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039751 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3948\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046291 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245208, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043157 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3947\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041388 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3942\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045558 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225424\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047358 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3948\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040650 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245208, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042508 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3947\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046079 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3942\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044917 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225424\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041709 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3948\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044822 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245208, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043074 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3947\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045877 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3942\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046519 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225424\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039865 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3948\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038076 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245208, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041620 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3947\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044713 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3942\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039977 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225424\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045838 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3948\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044335 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245208, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041657 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3947\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043321 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3942\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047935 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225424\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042347 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3948\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040603 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245208, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044677 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3947\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045056 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3942\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046693 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225424\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045187 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3948\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043315 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245208, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044942 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3947\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045888 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3942\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044887 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225424\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044911 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3948\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044144 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245208, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044937 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3947\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.037237 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3942\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042295 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225424\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045336 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3948\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.052321 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245208, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040717 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3947\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041230 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3942\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042140 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225424\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041014 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3948\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045136 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245208, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043636 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3947\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045103 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3942\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044577 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225424\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.049962 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3948\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041674 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245208, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040923 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3947\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041602 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3942\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041069 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225424\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043757 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3948\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040549 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245208, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044542 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3947\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043726 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3942\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044980 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225424\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043538 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3948\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047481 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245208, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042044 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3947\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044981 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3942\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045590 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225424\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045378 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3948\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044679 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245208, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046260 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3947\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.050226 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3942\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040813 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225424\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046013 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3948\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045024 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245208, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042301 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3947\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039774 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3942\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042256 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225424\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041902 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3948\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040465 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245208, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.048768 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3947\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044452 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3942\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045969 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225424\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040385 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3948\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040823 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245208, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042465 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3947\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039743 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3942\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041849 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225424\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045549 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3948\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046011 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245208, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043427 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3947\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045572 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3942\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042554 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225424\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041463 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3948\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044846 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245208, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038721 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3947\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045090 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3942\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044573 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225424\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047766 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3948\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044270 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245208, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043150 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3947\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042705 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3942\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041258 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225424\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045719 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3948\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043907 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245208, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043993 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3947\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042275 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3942\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045407 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225424\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044180 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3948\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044880 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245208, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039173 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3947\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043515 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3942\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044894 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225424\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039736 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3948\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041528 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245208, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042508 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3947\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.049898 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3942\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041404 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225424\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043731 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3948\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041002 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245208, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040755 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3947\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041546 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3942\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.048067 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225424\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046297 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3948\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044195 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245208, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047942 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3947\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045070 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3942\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039349 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225424\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045654 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3948\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045109 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245208, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043599 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3947\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044131 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3942\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044988 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225424\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040683 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3948\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043506 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245208, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040479 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3947\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044132 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3942\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044345 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225424\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043433 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3948\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043691 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245208, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042927 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3947\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043187 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3942\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045644 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225424\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047047 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3948\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043552 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245208, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042808 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3947\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041185 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3942\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043012 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225424\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043282 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3948\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043968 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245208, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040003 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3947\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041359 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3942\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044695 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225424\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039652 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3948\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041534 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245208, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044451 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3947\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045814 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3942\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040058 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225424\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046385 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3948\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045753 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245208, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044355 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3947\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045175 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3942\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044018 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225424\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043293 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3948\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042034 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245208, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039727 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3947\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044608 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3942\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042441 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225424\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045999 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3948\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044866 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245208, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.048750 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3947\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043596 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3942\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043920 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225424\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042557 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3948\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041210 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245208, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043661 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3947\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045685 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3942\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039110 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225424\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040499 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3948\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047905 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245208, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042604 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3947\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045949 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3942\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044445 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225424\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046414 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3948\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040142 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245208, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043332 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3947\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041352 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3942\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041499 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225424\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.048372 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3948\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044900 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245208, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043532 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3947\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047224 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3942\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 225423\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044283 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3951\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 19785, number of negative: 225424\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042656 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3948\n",
      "[LightGBM] [Info] Number of data points in the train set: 245209, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 24732, number of negative: 281779\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.049980 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3949\n",
      "[LightGBM] [Info] Number of data points in the train set: 306511, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "566.4901103973389\n"
     ]
    }
   ],
   "source": [
    "# DÃ©finir le modÃ¨le \n",
    "lightgbm = lgb.LGBMClassifier(class_weight='balanced')\n",
    "start = time.time()\n",
    "# DÃ©finir la grille des hyperparamÃ¨tres Ã  rechercher\n",
    "param_grid = {'boosting_type' : ['gbdt'], \n",
    "              'num_leaves' : [5, 10, 31,4, 5],\n",
    "              'max_depth' : [-1, 0, 10, 20], \n",
    "              'learning_rate' : [0.1, 0.5, 0.7]\n",
    "              #n_estimators=100\n",
    "             }\n",
    "\n",
    "\n",
    "# CrÃ©er l'objet GridSearchCV\n",
    "grid_search = GridSearchCV(lightgbm, param_grid, cv=5, scoring='roc_auc')\n",
    "\n",
    "# Adapter le modÃ¨le aux donnÃ©es d'entraÃ®nement\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Afficher les meilleurs paramÃ¨tres trouvÃ©s\n",
    "accuracy = grid_search.score(X_test, y_test)\n",
    "y_predict = grid_search.predict(X_test)\n",
    "temps = time.time() - start\n",
    "print(temps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f6699012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleurs paramÃ¨tres: {'boosting_type': 'gbdt', 'learning_rate': 0.1, 'max_depth': 10, 'num_leaves': 31}\n",
      "Meilleur accuracy: 0.7535442351292669\n",
      "PrÃ©cision sur l'AUC: 0.6806321205439176\n",
      "PrÃ©cision sur l'ensemble de test: 0.7431210062714135\n"
     ]
    }
   ],
   "source": [
    "print(\"Meilleurs paramÃ¨tres:\", grid_search.best_params_)\n",
    "print(\"Meilleur accuracy:\", grid_search.best_score_)\n",
    "print(\"PrÃ©cision sur l'AUC:\",roc_auc_score(y_test, y_predict))\n",
    "print(\"PrÃ©cision sur l'ensemble de test:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0511dac6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "82959f02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_predict)\n",
    "cm_matrix = pd.DataFrame(data=cm, columns=['Actual Positive:1', 'Actual Negative:0'], \n",
    "                                 index=['Predict Positive:1', 'Predict Negative:0'])\n",
    "\n",
    "sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "48a190d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pour mettre en place un predict proba avec un seuil de 0.6 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "76d6b5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    }
   ],
   "source": [
    "df_pred = pd.DataFrame(grid_search.predict_proba(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1b2f2f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(row):\n",
    "    if row[1]>=0.75 :\n",
    "         return 1\n",
    "    else :\n",
    "        return 0\n",
    "\n",
    "df_pred['pred_reel'] = df_pred.apply(lambda row : prediction(row),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4e1517ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, df_pred['pred_reel'])\n",
    "cm_matrix = pd.DataFrame(data=cm, columns=['Actual Positive:1', 'Actual Negative:0'], \n",
    "                                 index=['Predict Positive:1', 'Predict Negative:0'])\n",
    "\n",
    "sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9336e70a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25946d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "519f2826",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_39472\\3162077538.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# Adapter le modÃ¨le aux donnÃ©es d'entraÃ®nement\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m# Afficher les meilleurs paramÃ¨tres trouvÃ©s\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    889\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 891\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1390\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1391\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1392\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1394\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    836\u001b[0m                     )\n\u001b[0;32m    837\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 838\u001b[1;33m                 out = parallel(\n\u001b[0m\u001b[0;32m    839\u001b[0m                     delayed(_fit_and_score)(\n\u001b[0;32m    840\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1046\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1047\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1048\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 861\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    862\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    678\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 680\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    681\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"i\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 255\u001b[1;33m         \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m         \u001b[1;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    313\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_probB\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_status_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 315\u001b[1;33m         \u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibsvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    316\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# DÃ©finir le modÃ¨le \n",
    "svm = SVC(class_weight='balanced')\n",
    "\n",
    "# DÃ©finir la grille des hyperparamÃ¨tres Ã  rechercher\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100], \n",
    "              'kernel' : ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "             }\n",
    "\n",
    "\n",
    "# CrÃ©er l'objet GridSearchCV\n",
    "grid_search = GridSearchCV(svm, param_grid, cv=5, scoring='roc_auc')\n",
    "\n",
    "# Adapter le modÃ¨le aux donnÃ©es d'entraÃ®nement\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Afficher les meilleurs paramÃ¨tres trouvÃ©s\n",
    "accuracy = grid_search.score(X_test, y_test)\n",
    "y_predict = grid_search.predict(X_test)\n",
    "temps = time.time() - start\n",
    "print(temps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdbd79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Meilleurs paramÃ¨tres:\", grid_search.best_params_)\n",
    "print(\"Meilleur accuracy:\", grid_search.best_score_)\n",
    "print(\"PrÃ©cision sur l'AUC:\",roc_auc_score(y_test, y_predict))\n",
    "print(\"PrÃ©cision sur l'ensemble de test:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fc144f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_predict)\n",
    "cm_matrix = pd.DataFrame(data=cm, columns=['Actual Positive:1', 'Actual Negative:0'], \n",
    "                                 index=['Predict Positive:1', 'Predict Negative:0'])\n",
    "\n",
    "sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2966381c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1829124",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f64001c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
